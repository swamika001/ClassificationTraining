{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 3 : Méthodologie de validation et test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choix de la fonction à apprendre pour l'exemple : ici un polynome de degré 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listeParamPoly = [0.03, 0.2, -1, -10, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(N):\n",
    "    x = np.random.uniform(-10,10,N)\n",
    "    y = np.polyval(listeParamPoly,x) + np.random.normal(0.0, 15.0, N)\n",
    "    return x.reshape(-1, 1), y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction permettant de calculer les intervalles de confiance de notre métrique (ici la [MSE](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_interval(y, y_pred):\n",
    "    n = len(y)\n",
    "    s = np.sqrt(np.var(mean_squared_error(np.expand_dims(y,1).transpose(), np.expand_dims(y_pred,1).transpose(),\n",
    "                          multioutput='raw_values'), ddof=1))\n",
    "    return 1.96*s/np.sqrt(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Génération des données : Choisir le nombre de points à utiliser :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPoints = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = generate_data(dataPoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(X, y, 'o')\n",
    "ax.plot(np.linspace(-10,10,100), np.polyval(listeParamPoly,np.linspace(-10,10,100)), color='black', linewidth=3)\n",
    "ax.set_title('Data set')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_xlabel('x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définition des fonctions de caractéristiques\n",
    "\n",
    "Reprenez ici vos fonctions de caractéristiques de l'exercice précédent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = [\n",
    "       lambda x: x**0, \n",
    "       lambda x: x**1,\n",
    "       lambda x: x**2,\n",
    "       lambda x: x**3,\n",
    "       lambda x: np.abs(x),\n",
    "       lambda x: x > -5.0,\n",
    "       lambda x: x > 0.0,\n",
    "       lambda x: x > 5.0,\n",
    "       lambda x: np.cos(0.1*x),\n",
    "       lambda x: np.cos(x),\n",
    "       lambda x: np.sin(0.1*x),\n",
    "       lambda x: np.sin(x),\n",
    "      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_space_projection(X, phi):\n",
    "    X_features = []\n",
    "    for i in range(0, len(phi)):\n",
    "        X_features.append(np.apply_along_axis(phi[i], 0, X))\n",
    "    X_augmented = np.concatenate(X_features, axis=1)\n",
    "    return X_augmented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation des données test\n",
    "\n",
    "Après projection dans l'espace des caractéristiques, nous découpons notre dataset en trois parties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feature_space_projection(X, phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splits : train(50%) - validation(25%) - test(25%)\n",
    "\n",
    "Un ensemble d'entrainement, un ensemble de validation qui va nous permettre d'évaluer nos modèles et de choisir notre préféré sur un ensemble de données jamais vu, et un ensemble de test pour l'évaluation final en mode *réel*.\n",
    "\n",
    "Remarquez que *théoriquement*, l'ensemble de valiation et l'ensemble de test sont identiques (sous l'hypothèse [IID](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables)) et peuvent être permutés sans problème pour la méthodologie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_, X_test, y_, y_test = train_test_split(X, y, test_size=0.25)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_, y_, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement du modèle sur les données d'entraînement\n",
    "\n",
    "Vous pouvez ici changez les hyper-paramètres pour en voir l'effet sur les différentes erreurs sur les différents sous-ensembles de données. Vous pouvez aussi essayer d'autres modèles linéaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg2 = linear_model.ElasticNet(alpha=0.001, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
    "      max_iter=100000, normalize=False, positive=False, precompute=False,\n",
    "      random_state=None, selection='random', tol=0.0001, warm_start=False)\n",
    "reg2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Évaluation du modèle sur l'ensemble d'entraînement (training loss, erreur d'entrainement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = reg2.predict(X_train)\n",
    "training_error = mean_squared_error(y_train, y_train_pred)\n",
    "print(\"L'erreur d'entraînement du modèle appris est : %5.2f\" % training_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Évaluation du modèle sur l'ensemble de validation (validation loss, erreur de validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = reg2.predict(X_validation)\n",
    "validation_error = mean_squared_error(y_validation, y_val_pred)\n",
    "print(\"L'erreur de validation du modèle appris est : %5.2f\" % validation_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Évaluation du modèle sur l'ensemble de test (test loss, erreur de test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = reg2.predict(X_test)\n",
    "test_error = mean_squared_error(y_test, y_test_pred)\n",
    "print(\"L'erreur de test du modèle appris est : %5.2f\" % test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation du vrai risque du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_risk, y_risk = generate_data(1000000)\n",
    "X_risk = feature_space_projection(X_risk, phi)\n",
    "y_risk_pred = reg2.predict(X_risk)\n",
    "true_risk = mean_squared_error(y_risk, y_risk_pred)\n",
    "print(\"L'erreur de généralisation du modèle appris est : %5.2f ± %2.2f\" % (true_risk, confidence_interval(y_risk, y_risk_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on se rappelle que l'ensemble de test et de validation sont statistiquement identiques, on concoit aisément que l'estimation du vrai risque est toujours très difficile et potentiellement éloignée de l'erreur de validation ou de celle de test. \n",
    "\n",
    "On a *optimisé* plusieurs modèles sur l'ensemble d'entrainement, qu'on en a *choisi* les hyperparamètres d'apprentissage optimaux sur l'ensemble de validation et qu'on a vérifié nos choix **une seule fois** sur l'ensemble de test. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
