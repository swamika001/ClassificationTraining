{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 2 : Augmentation de la capacité d'un modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choix de la fonction à apprendre pour l'exemple : ici un polynome de degré 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listeParamPoly = [0.03, 0.2, -1, -10, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(N):\n",
    "    x = np.random.uniform(-10,10,N)\n",
    "    y = np.polyval(listeParamPoly,x) + np.random.normal(0.0, 15.0, N)\n",
    "    return x.reshape(-1, 1), y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Génération des données : Choisir le nombre de points à utiliser :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPoints = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = generate_data(dataPoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(X, y, 'o')\n",
    "ax.plot(np.linspace(-10,10,100), np.polyval(listeParamPoly,np.linspace(-10,10,100)), color='black', linewidth=3)\n",
    "ax.set_title('Data set')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_xlabel('x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définition des fonctions de caractéristiques\n",
    "\n",
    "Ajoutez dans le vecteur $\\varphi$ autant de fonctions caractéristiques que vous le souhaitez. Idéalement non-linéaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = [\n",
    "       lambda x: x**0, \n",
    "       lambda x: x**1,\n",
    "       lambda x: x**2,\n",
    "       lambda x: x**3,\n",
    "       lambda x: np.abs(x),\n",
    "       lambda x: x > -5.0,\n",
    "       lambda x: x > 0.0,\n",
    "       lambda x: x > 5.0,\n",
    "       lambda x: np.cos(0.1*x),\n",
    "       lambda x: np.cos(x),\n",
    "       lambda x: np.sin(0.1*x),\n",
    "       lambda x: np.sin(x),\n",
    "      ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va utiliser ce vecteur pour faire la projection. Voici la fonction de projection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_space_projection(X, phi):\n",
    "    X_features = []\n",
    "    for i in range(0, len(phi)):\n",
    "        X_features.append(np.apply_along_axis(phi[i], 0, X))\n",
    "    X_augmented = np.concatenate(X_features, axis=1)\n",
    "    return X_augmented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul de la projection dans l'espace des caractéristiques\n",
    "\n",
    "Calcul de la projection puis affichage de notre entrée dans le nouvel espace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_augmented = feature_space_projection(X, phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_augmented[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entraînement du modèle\n",
    "\n",
    "Maintenant qu'on a ouvert la boîte à l'exercice précédent, on va utiliser le modèle de regression linéaire [`linear_model.LinearRegression()`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression) de `scikit-learn`. On pourrait utiliser d'autres modèles [linéaires](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X_augmented, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul de l'erreur sur l'ensemble d'entraînement vs le \"vrai\" risque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erreur d'entraînement\n",
    "\n",
    "Calcul de la fonction de perte [MSE](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) sur les données d'entrainement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_augmented)\n",
    "training_error = mean_squared_error(y, y_pred)\n",
    "print(\"L'erreur d'entraînement du modèle appris est : %5.2f\" % training_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation du vrai risque\n",
    "\n",
    "Et si on valide (non réalistiquement) sur la *vraie* distribution des données:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test = generate_data(10000000)\n",
    "X_test_augmented = feature_space_projection(X_test, phi)\n",
    "y_test_pred = reg.predict(X_test_augmented)\n",
    "test_error = mean_squared_error(y_test, y_test_pred)\n",
    "print(\"Vrai risque du modèle appris est : %5.2f\" % test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention au sur-apprentissage\n",
    "\n",
    "Lorsque le nombre de caractéristiques utilisé est très important, la capacité augmente énormément jusqu'à apprendre *par coeur* les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(X, y, 'o')\n",
    "ax.set_title('Polynôme')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_xlabel('x')\n",
    "\n",
    "linspace_x = np.linspace(-10, 10, num=100000)\n",
    "linspace_x = np.expand_dims(linspace_x, axis=1)\n",
    "\n",
    "linspace_X_augmented = feature_space_projection(linspace_x, phi)\n",
    "\n",
    "y_pred = reg.predict(linspace_X_augmented)\n",
    "ax.plot(linspace_x, y_pred, color='red', linewidth=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Régularisation et hyperparamètres\n",
    "\n",
    "Il nous faut alors soit réduire le nombres de caractéristiques (et donc la dimensionnalité de l'espace de projection), soit *régulariser* nos paramètres pour assurer une bonne *généralisation*.\n",
    "\n",
    "On va utiliser ici [ElasticNet](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html#sklearn.linear_model.ElasticNet) de `scikit-learn` qui permet de combiner les normes $L_1$ et $L_2$ pour la régularisation.\n",
    "\n",
    "Vous pouvez chosir ici le taux de régularisation et la proportion de régularisation $L_1$ vs $L_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taux_de_regularisation = 0.001\n",
    "ratio_normes = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit ensuite le modèle et on l'entraine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg2 = linear_model.ElasticNet(alpha=taux_de_regularisation, copy_X=True, fit_intercept=True, l1_ratio=ratio_normes,\n",
    "      max_iter=10000, normalize=False, positive=False, precompute=False,\n",
    "      random_state=None, selection='random', tol=0.0001, warm_start=False)\n",
    "reg2.fit(X_augmented, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul du risque empirique : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'erreur d'entraînement du modèle appris est : 144.59\n"
     ]
    }
   ],
   "source": [
    "y_pred = reg2.predict(X_augmented)\n",
    "training_error = mean_squared_error(y, y_pred)\n",
    "print(\"L'erreur d'entraînement du modèle appris est : %5.2f\" % training_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul du *vrai* risque:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test = generate_data(1000000)\n",
    "X_test_augmented = feature_space_projection(X_test, phi)\n",
    "y_test_pred = reg2.predict(X_test_augmented)\n",
    "test_error = mean_squared_error(y_test, y_test_pred)\n",
    "print(\"Vrai risque du modèle appris est : %5.2f\" % test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichage du modèle régularisé :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(X, y, 'o')\n",
    "ax.set_title('Polynôme')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_xlabel('x')\n",
    "\n",
    "linspace_x = np.linspace(-10, 10, num=100000)\n",
    "linspace_x = np.expand_dims(linspace_x, axis=1)\n",
    "\n",
    "linspace_X_augmented = feature_space_projection(linspace_x, phi)\n",
    "\n",
    "y_pred = reg2.predict(linspace_X_augmented)\n",
    "ax.plot(linspace_x, y_pred, color='red', linewidth=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choix fait des paramètres de régularisation par ElasticNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reg2.coef_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
